\section{ Обзор источников }\label{sec:litreview}

Проблема качественного OCR в различных языках (в частности, в японском) стоит достаточно давно, и существует множество различных подходов к её решению. Большинство подходов основываются на применении различных методов машинного обучения, таких как $n$-граммные модели, нейросети, модели Маркова и т.д. 

В силу особенностей японского языка (см. \cref{sec:japanese}), а именно отсутствия словного деления в текстах, существующие методы исправления ошибок OCR можно разделить на 2 класса: использующие информацию о словном делении и не использующие её.

\subsection{ Методы, не использующие словное деление }

Идея подобных методов заключается в том, чтобы, не тратя ресурсы на определение границ слов в тексте, оперировать предложениями (границы которых выделяются достаточно легко) как единицами трансляции, и исправлять возможные ошибки OCR, не углубляясь в членение предложений.

Этот подход не слишком популярен, но применяется, например, в \cite{last} для задачи машинного перевода без привлечения словного деления, что авторы особенно подчёркивают.

Стоит также заметить, что настоящая работа может быть отнесена к этому классу.

\subsection{ Методы, использующие словное деление }

Информация о словном делении текста даёт удобный контекст для выделения признаков и настройки параметров при машинном обучении. Но эту информацию надо откуда-то получать, что приводит к делению алгоритмов на 2 этапа:

\begin{itemize}
	\item Получение словного деления. Может производиться с помощью специализированных алгоритмов (например, модификаций алгоритма Витерби, как в \cite{nagata:context}, или марковских случайных полей (conditional random fields, CRFs), как в \cite{kudo:crfs}), а также путём анализа конкретных языковых конструкций (например, bunsetsu boundaries, см. \cite{chung:bunsetsu}).
	
	Кроме того, словное деление может быть получено путём использования в работе предварительно размеченного корпуса, в разметке которого есть словное деление. В качестве примеров таких корпусов можно привести EDR Japanese Corpus (см. \cite{corpus:edr}), ATR Dialogue Database (см. \cite{corpus:atr}) и т.д.
	
	\item Применение словного деления как контекста для детектирования ошибок OCR. Достоверная информация о словном делении позволяет считать слова единицами трансляции, не теряя контекста предложения. Это даёт возможность получить больше признаков для машинного обучения. Подобный подход представлен в статье \cite{nagata:shape}, где используются $n$-граммные модели с backoff и различными подходами к сглаживанию (Good-Turing, Witten-Bell). 
\end{itemize}

Обзору основных актуальных методов исправления ошибок OCR в японском также целиком посвящена статья \cite{das:survey}.