
\section{ Анализ результатов }\label{sec:analysis}

В итоге оптимальной была признана модель Катца с глубиной бора $n=5$, результаты которой ещё улучшились после добавления опции отказа от классификации при недостаточной уверенности.

\begin{tabular}{|c|c|c|c|}\hline
	$M \backslash N$ & \KG & \BS & \MX \\ \hline
	Katz($n=5, C=1.0$)			 & 0.961 & 0.965 & 0.962 \\
	Katz($n=5, C=0.97$)	 & 0.966  & 0.986 & 0.967 \\ \hline 	
\end{tabular}

Проанализируем эти цифры глубже.

\subsection{ Сравнение с другими методами }

Сравним наши результаты с результатами решения аналогичной задачи через нейросети (\todo{конкретика, Даниил?}): 

\begin{tabular}{|c|c|c|c|}\hline
	$M \backslash $ & Certain accuracy & Classification rate & Uncertain accuracy \\ \hline
	NN	 & 0.976  & 0.77  & 0.73 \\
	Katz	 & 0.967  & 0.77 & 0.72  \\ \hline 	
\end{tabular}

Видно, что модель, основанная на $n$-граммах, ведёт себя неплохо по сравнению с рекуррентной нейросетью.

\todo{а надо ли тут писать больше?}

\subsection{ Анализ ошибок }

Если доля правильных выборов -- $97 \%$, то доля неправильных -- $3 \%$. Чем можно объяснить 3 \% ошибок?

\paragraph{ Нехватка информации } В условиях ручной генерации тестовых выборок (т.е. отсутствия отрицательных примеров для обучения) и $n$-граммной модели при рассмотрении эталонного и зашумлённого вариантов предложения зашумлённый всегда предполагается неверным. При этом, безусловно, существуют случаи, когда зашумлённый вариант встречается чаще, чем эталонный (значит, он наверняка возможен), из-за этого побеждает эталонный вариант при оценивании и решение классификатора считается неверным.
	
Приведём пример: 

\begin{tabular}{|c|c|c|} \hline
	Тип & Предложение & Оценка \\ \hline
	Эталон & \begin{CJK}{UTF8}{min} ご要望\colorbox{yellow}{\textbf{に}}あわせて、勉強会を開催。 \end{CJK} & 56 \\
	Шум & \begin{CJK}{UTF8}{min} ご要望\colorbox{yellow}{\textbf{な}}あわせて、勉強会を開催。 \end{CJK} & 63 \\ \hline
\end{tabular}

%\paragraph{ Несовершенность модели }

\todo{что ещё?}